---
- name: set /etc/NetworkManager/NetworkManager.conf
  blockinfile: 
    dest="/etc/NetworkManager/NetworkManager.conf" 
    insertafter="plugins=ifcfg-rh"
    content="dns=none\nrc-manager=unmanaged"
  notify:
     - restart NetworkManager
  when: ansible_distribution == "CentOS" and ansible_distribution_major_version == "7"
  tags: 
    - hadoop
    - hadoop_hosts
    
    
- name: stop nscd service 
  service: name=nscd state=stopped enabled=false
  when: ansible_distribution == "CentOS" and ansible_distribution_major_version == "6"
  tags: 
    - hadoop
    - hadoop_hosts

- name: set hostname
  hostname: name={{ host_name }}
  when:  inventory_hostname in groups.allnodes
  tags:
    - hadoop_hosts
    - hadoop


- name: copy hosts file.
  template: src=hosts.j2 dest=/etc/hosts backup=no owner=root group=root mode=0744
  tags:
    - hadoop
    - hadoop_hosts

- set_fact:
    hadoop_package_name: hadoop-{{ hadoop.version }}.tar.gz
    hadoop_application_path: "{{ hadoop.installation_path }}/hadoop-{{ hadoop.version }}"
  tags: 
    - hadoop
    - hadoop_installation

- name: check hadoop package
  stat: path={{ package_download_path }}/{{ hadoop_package_name }}
  register: hadoop_package_exists
  tags:
    - hadoop
    - hadoop_installation
# download only in the ansible master node
- name: download hadoop tar if not downloaded
  get_url: url={{ hadoop.download_mirror }}/hadoop-{{ hadoop.version }}/{{ hadoop_package_name }} dest={{ package_download_path }}
  register: result
  until: result|success
  retries: 5
  delay: 2
  when: not hadoop_package_exists.stat.exists
  tags: 
    - hadoop
    - hadoop_installation

# other nodes wait for it
#- local_action: wait_for path={{ package_download_path }}/{{ hadoop_package_name }}
#  when: not groups.namenodes
#  tags: hadoop


#- copy: src={{ package_download_path }}/{{ hadoop_package_name }} dest={{ package_download_path }}/{{ hadoop_package_name }} force=no
#  tags: hadoop

- name: unarchive hadoop package
  unarchive: src={{ package_download_path }}/{{ hadoop_package_name }} dest={{ hadoop.installation_path }} copy=no 
  tags: 
    - hadoop
    - hadoop_installation

- name: delete package downloaded if needed
  file: path={{ package_download_path }}/{{ hadoop_package_name }} state=absent
  when: force_cleanup is defined and force_cleanup == "True"
  tags:
    - hadoop
    - hadoop_installation

- name: create softlink for apache hadoop
  file: src={{ hadoop.installation_path }}/hadoop-{{ hadoop.version }} dest={{ hadoop.installation_path }}/hadoop state=link
  tags:
    - hadoop
    - hadoop_installation

- name: Create folder /etc/hadoop
  file: path=/etc/hadoop state=directory owner={{ hdfs_user }} group={{ hdfs_group }}
  tags:
    - hadoop
    - hadoop_installation

- name: Create hadoop link for conf to /etc/hadoop
  file: src={{ hdfs_conf_dir }} dest=/etc/hadoop/conf owner={{ hdfs_user }} group={{ hdfs_group }} state=link
  tags:
    - hadoop
    - hadoop_installation

- name: Create link for hdfs to /usr/local/bin
  file: src={{ hdfs_bin_dir }}/hdfs dest=/usr/local/bin/hdfs owner={{ hdfs_user }} group={{ hdfs_group }} mode=0755 state=link
  tags:
    - hadoop
    - hadoop_installation

- name: Create link for hadoop to /usr/local/bin
  file: src="{{hdfs_bin_dir}}/hadoop" dest=/usr/local/bin/hadoop owner={{ hdfs_user }} group={{ hdfs_group }} mode=0755 state=link
  tags:
    - hadoop
    - hadoop_installation

- name: Export hadoop variables
  copy: content="export HADOOP_HOME={{ hadoop.installation_path}}/hadoop-{{ hadoop.version }}\nexport HADOOP_PREFIX={{ hadoop.installation_path}}/hadoop-{{ hadoop.version }}\nexport HADOOP_CONF_DIR={{ hdfs_conf_dir }}\nexport HADOOP_COMMON_LIB_NATIVE_DIR={{ hadoop.installation_path}}/hadoop-{{ hadoop.version }}/lib/native\nexport HADOOP_OPTS=-Djava.library.path={{ hadoop.installation_path}}/hadoop-{{ hadoop.version }}/lib/native\nexport HADOOP_LIBEXEC_DIR={{ hadoop.installation_path}}/hadoop-{{ hadoop.version }}/libexec" dest="/etc/profile.d/hadoop_exports.sh" mode=0755
  tags:
    - hadoop
    - hadoop_installation

- name: Allow hadoop variables keeping for sudoers
  template: src=hadoop_sudoers.j2 dest=/etc/sudoers.d/hadoop owner=root group=root mode=0644
  tags:
    - hadoop
    - hadoop_installation

# rack awareness script: see https://bigdataprocessing.wordpress.com/2013/07/30/hadoop-rack-awareness-and-configuration/)
# and templates/rack-awareness.sh.j2
# if this is not defined, the hdfs will not be rack aware. DO NOT USE SINGLE QUOTES (or make sure it works)
# hdfs_rack_script_awk: '"{if ($4 < 3) print "rack-1"; else print "rack-2" }"'

- name: Create hadoop log dir
  file: path={{ hdfs_log_dir }} state=directory owner={{ hdfs_user }} group={{ hdfs_group }} mode=0755
  tags:
    - hadoop
    - hadoop_installation

- name: Create directory for unix sockets
  file: path={{ hdfs_dfs_domain_socket_path_folder }} state=directory owner={{ hdfs_user }} group=root mode=0755
  when: hdfs_enable_short_circuit_reads
  tags:
    - hadoop
    - hadoop_installation


- name: Set JAVA_HOME in Apache Hadoop environment.
  lineinfile: dest="{{ hdfs_conf_dir }}/hadoop-env.sh" regexp="^export JAVA_HOME=" line="export JAVA_HOME=/usr/java/latest\nexport HADOOP_LOG_DIR={{ hdfs_log_dir }}"
  notify:
   - Restart namenode
   - Restart secondary namenode
   - Restart datanode
   - Restart journalnode
   - Restart zkfc 
  tags:
   - hadoop
   - hadoop_configuration


- name: Configure core.
  template: src=core-site.xml.j2 dest="{{ hdfs_conf_dir }}/core-site.xml" owner={{ hdfs_user }} group={{ hdfs_group }} mode=0644
  notify:
   - Restart namenode
   - Restart secondary namenode
   - Restart datanode
   - Restart journalnode
   - Restart zkfc 
  tags:
   - hadoop
   - hadoop_configuration
  
- name: Configure Apache HDFS.
  template: src=hdfs-site.xml.j2 dest="{{ hdfs_conf_dir }}/hdfs-site.xml" backup=no owner={{ hdfs_user }} group={{ hdfs_group }} mode=0644
  notify:
   - Restart namenode
   - Restart secondary namenode
   - Restart datanode
   - Restart journalnode
   - Restart zkfc 
  tags:
   - hadoop
   - hadoop_configuration

- name: Configure Apache Yarn.
  template: src=yarn-site.xml.j2 dest="{{ hdfs_conf_dir }}/yarn-site.xml" owner={{ yarn_user }} group={{ hdfs_group }} mode=0644
  notify:
   - Restart resoucemanager
   - Restart nodemanager
  when: inventory_hostname in hdfs_resourcemanager
  tags:
   - hadoop
   - yarn_configuration

- name: set Yarn-env log dir
  blockinfile: 
    dest="{{ hdfs_conf_dir }}/yarn-env.sh" 
    insertafter="IFS="
    content="YARN_LOG_DIR={{yarn_log_dir}}\nexport JAVA_HOME=/usr/java/latest"
  notify:
   - Restart resoucemanager
   - Restart nodemanager
  when: inventory_hostname in hdfs_resourcemanager
  tags: 
   - hadoop
   - yarn_configuration

- name: Configure log4j.properties
  template: src=log4j.properties.j2 dest={{ hdfs_conf_dir }}/log4j.properties owner={{ hdfs_user }} group={{ hdfs_group }} mode=0755
  notify:
   - Restart namenode
   - Restart secondary namenode
   - Restart datanode
   - Restart journalnode
   - Restart zkfc
  tags:
   - hadoop
   - hadoop_configuration
