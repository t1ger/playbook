---
#------------------------------------------------------------------------------
# General cluster settings
#------------------------------------------------------------------------------
hdfs_cluster_name: cluster1
hdfs_user: hdfs
hdfs_group: hadoop
hdfs_user_home: "/var/lib/hadoop-{{ hdfs_user }}"

yarn_user: yarn
yarn_user_home: "/var/lib/hadoop-{{ yarn_user }}"

mapred_user: mapred
mapred_user_home: "/var/lib/hadoop-mapreduce"


hdfs_ssh_known_hosts_file: "{{ hdfs_user_home }}/.ssh/known_hosts"

# Redistribute ssh keys every time?
hdfs_redistribute_ssh_keys: False

#------------------------------------------------------------------------------
# Hadoop installation source
#------------------------------------------------------------------------------
hdfs_distribution_method: "download"   # Method to use for archive installation ("download", "local_file" or "compile")


# Bootstraps the cluster ( Format namenodes, zkfc, journalnodes, start all services)
# Please read the code before you activate this option.
# Especially if you already have a hadoop setup in place.
hdfs_bootstrap: false

# Use ansible handlers?
hdfs_ansible_handlers: True

#------------------------------------------------------------------------------
# Hadoop configuration
#------------------------------------------------------------------------------

# Symlink for hadoop to the version you are installing
hdfs_hadoop_home: "{{ hadoop.installation_path }}/hadoop"
hdfs_conf_dir: "{{hdfs_hadoop_home}}/etc/hadoop"
hdfs_bin_dir: "{{hdfs_hadoop_home}}/bin"
hdfs_log_dir: /var/log/hadoop
hdfs_tmpdir: "/tmp"
yarn_log_dir: /var/log/hadoop-yarn/apps

# Directories where namenode should store metadata
hdfs_namenode_dir_list:
 - "/tmp/dfs/name"
# Directories where secondary namenode should store temporary images to merge
hdfs_namenode_checkpoint_dir_list:
 - "/tmp/dfs/secondaryname"
# Directories where datanodes should store data
hdfs_datanode_dir_list:
 - "/tmp/dfs/data"

# Directories where journal nodes should store edits
hdfs_dfs_journalnode_edits_dir: "/tmp/dfs/journaldir"
hdfs_dfs_journalnode_edits_dir_perm: "700"

hdfs_enable_short_circuit_reads: false  # IMPORTANT: this property should be 'true' or 'false'

#------------------------------------------------------------------------------
# Extended core-site.xml
#------------------------------------------------------------------------------
hdfs_tmpdir_user: "{{hdfs_tmpdir}}/hadoop-${user.name}"
hdfs_fs_trash_interval: 0
hdfs_fs_trash_checkpoint_interval: 0 # If 0 this is set to the value of hdfs_fs_trash_interval by hadoop

#core_site_additional_properties:
# - {name: fs.s3a.awsAccessKeyId, value: dsfds, final: true}
# - {name: fs.s3a.awsSecretAccessKey, value: dsfds, final: true}


#------------------------------------------------------------------------------
# Hadoop host variables
#------------------------------------------------------------------------------
hdfs_namenodes: "{{ groups.namenodes }}"
hdfs_hadoop_hosts: "{{ groups.hadoop }}"
hdfs_journalnodes: "{{ groups.journalnodes }}"
hdfs_secondary_namenode: "{{ groups.secondarynamenode if groups.secondarynamenode is defined else [] }}"
hdfs_datanodes: "{{ groups.datanodes }}"
hdfs_zookeeper_hosts: "{{ groups.zk_servers }}"
hdfs_resourcemanager: "{{ groups.yarnresourcemanager }}"
hdfs_nodemanager: "{{ groups.yarnnodemanager }}"

#------------------------------------------------------------------------------
# Hadoop native libraries (experimental)
#------------------------------------------------------------------------------
hdfs_compile_from_source: "{{ hdfs_distribution_method == 'compile' }}"
hdfs_compile_node: "{{ hdfs_namenodes[0] }}"
hdfs_compile_from_git: True
hdfs_compile_version: "tags/rel/release-{{ hadoop.version }}"
hdfs_fetch_folder: /tmp/ansible_fetch



#------------------------------------------------------------------------------
# Extended hdfs-site.xml
#------------------------------------------------------------------------------

hdfs_fs_permissions_umask_mode: "002"
hdfs_dfs_permissions_superusergroup: "{{hdfs_group}}"
hdfs_dfs_blocksize: 134217728
hdfs_dfs_namenode_write_stale_datanode_ratio: "0.5f"
hdfs_dfs_datanode_du_reserved: "1073741824"
hdfs_dfs_datanode_data_dir_perm: "700"
hdfs_dfs_datanode_max_transfer_threads: 4096
hdfs_dfs_replication: 2
hdfs_dfs_replication_max: 50
hdfs_dfs_namenode_replication_min: 1
hdfs_dfs_namenode_checkpoint_period: 3600
# the recommended 'namenode handler count' is best defined by formula: lb(#datanodes) * 20
# and recommended 'service handler count'  50% of the previous value
# Ref: https://community.hortonworks.com/articles/43839/scaling-the-hdfs-namenode-part-2.html
# -> for an average cluster 10-20 DNs the value 64 is a good average (for 32+ DNs -> 100+)
hdfs_dfs_namenode_handler_count: 32
hdfs_dfs_namenode_service_handler_count: "{{ (hdfs_dfs_namenode_handler_count / 2)|int}}"
hdfs_dfs_namenode_avoid_read_stale_datanode: true
hdfs_dfs_namenode_avoid_write_stale_datanode: true
hdfs_dfs_namenode_audit_log_async: false
hdfs_dfs_client_file_block_storage_locations_num_threads: 10
hdfs_dfs_client_file_block_storage_locations_timeout_millis: 1000
hdfs_dfs_domain_socket_path_folder: /var/lib/hadoop-hdfs
hdfs_namenode_datanode_registration_ip_hostname_check: false


#------------------------------------------------------------------------------
# HA specific setup
#------------------------------------------------------------------------------
# Use ssh as fencing method (other option is shell(/bin/true)
hdfs_ssh_fence: True

hdfs_ha_enabled: "{{hdfs_namenodes | count > 1}}"
hdfs_default_name: "hdfs://{{ hdfs_nameservices if hdfs_ha_enabled else hdfs_namenodes[0] + ':8020' }}"
hdfs_default_fs: "{{hdfs_default_name}}"
hdfs_nameservices: "{{hdfs_cluster_name}}"
hdfs_zookeeper_client_port: 2181
hdfs_zookeeper_quorum: "{{ hdfs_zookeeper_hosts | join(':' + (hdfs_zookeeper_client_port | string) + ',')  }}:{{ hdfs_zookeeper_client_port | string }}"


#------------------------------------------------------------------------------
# Non-HA specific setup
#------------------------------------------------------------------------------
hdfs_secondary_namenode_http_address: "0.0.0.0:50090"

# Nodes for decomissioning:
#dfs_hosts_exclude:
# - t03

#hdfs_site_additional_properties:
# - {name: dfs.namenode.stale.datanode.interval, value: 30000}

#------------------------------------------------------------------------------
# Rack specific
#------------------------------------------------------------------------------

# rack awareness script: see https://bigdataprocessing.wordpress.com/2013/07/30/hadoop-rack-awareness-and-configuration/)
# and templates/rack-awareness.sh.j2
# if this is not defined, the hdfs will not be rack aware. DO NOT USE SINGLE QUOTES (or make sure it works)
# hdfs_rack_script_awk: '"{if ($4 < 3) print "rack-1"; else print "rack-2" }"'
hdfs_rack_script_path: "{{hdfs_conf_dir}}/rack-awareness.sh"



#------------------------------------------------------------------------------
# log4j.properties vars
#------------------------------------------------------------------------------

hadoop_log_maxfilesize: "256MB"
hadoop_log_maxbackupindex: 20


#--------------------
# yarn-site.xml vars
#---------------------
# yarn directories. A comma seperated lists local to yarn instances
yarn_nodemanager_local_dirs: "/var/lib/hadoop-yarn/cache/${user.name}/nm-local-dir"
yarn_nodemanager_log_dirs: "/var/log/hadoop-yarn/containers"

# yarn memory settings in Mb
yarn_nodemanager_resource_memory: 4096

# yarn cpu-vcores
yarn_nodemanager_resource_cpu: 10



#------------------------------------------------------------------------------
# HA specific setup for yarn-resoucemanager
#------------------------------------------------------------------------------

yarn_ha_enabled: "{{ groups['yarnresourcemanager']| count > 1}}"
yarn_ha_automatic_failover_enabled: true
yarn_ha_automatic_failover_embedded: true

yarn_default_name: "hdfs://{{ hdfs_nameservices if hdfs_ha_enabled else hdfs_namenodes[0] + ':8020' }}"
yarn_nameservices: "{{hdfs_cluster_name}}"
#yarn_zookeeper_client_port: 2181
#yarn_zookeeper_quorum: "{{ hdfs_zookeeper_hosts | join(':' + (yarn_zookeeper_client_port | string) + ',')  }}:{{ yarn_zookeeper_client_port | string }}"


# Using the value 1 in order to avoid swapping and OOMs, since servers should have plenty of memory.
kernel_swappiness: 1

# Open file limits.
limits_nofile_hard: 65536
limits_nofile_soft: 65536



